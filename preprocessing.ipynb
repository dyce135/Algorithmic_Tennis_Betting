{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:16.837200Z",
     "end_time": "2023-04-28T16:14:17.218110Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import markov_sim as markov\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from hampel import hampel\n",
    "import time\n",
    "import copy\n",
    "import preprocessing as p\n",
    "import score_inference as score\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0'\n",
    "os.environ['LD_LIBRARY_PATH'] = '$LD_LIBRARY_PATH:/opt/rocm-5.3.0/lib'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:17.566790Z",
     "end_time": "2023-04-28T16:14:17.594527Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    data_list = []\n",
    "    for line in open(file, 'r'):\n",
    "        data_list.append(json.loads(line))\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        top = f.readline()\n",
    "        top = json.loads(top)\n",
    "\n",
    "    runner_id = top['mc'][0]['marketDefinition']['runners'][0]['id']\n",
    "    runner_id_2 = top['mc'][0]['marketDefinition']['runners'][1]['id']\n",
    "    market_datetime = parser.parse(data_list[-1]['mc'][0]['marketDefinition']['marketTime'])\n",
    "    r1_result = data_list[-1]['mc'][0]['marketDefinition']['runners'][0]['status']\n",
    "    market_timestamp = datetime.timestamp(market_datetime) * 1000\n",
    "    return data_list, runner_id, runner_id_2, r1_result, market_timestamp\n",
    "\n",
    "\n",
    "def get_list(runner_id, data_list, market_timestamp):\n",
    "    # Create list for each runner\n",
    "    runner_list = []\n",
    "    for instance in data_list:\n",
    "        if instance['pt'] > market_timestamp:\n",
    "            if instance['mc'][0]['rc']:\n",
    "                # Check for runner id\n",
    "                temp_dict = {k: v for (k, v) in instance['mc'][0]['rc'][0].items() if v == runner_id}\n",
    "                if temp_dict:\n",
    "                    # Append runner info\n",
    "                    runner_list.append([instance['mc'][0]['rc'][0], instance['pt']])\n",
    "                elif len(instance['mc'][0]['rc']) > 1:\n",
    "                    # If more than one runner\n",
    "                    temp_dict_2 = {k: v for (k, v) in instance['mc'][0]['rc'][1].items() if v == runner_id}\n",
    "                    if temp_dict_2:\n",
    "                        runner_list.append([instance['mc'][0]['rc'][1], instance['pt']])\n",
    "    return runner_list\n",
    "\n",
    "\n",
    "def convert_odds(runner_list):\n",
    "    # Convert to back/lay/last traded odds\n",
    "\n",
    "    list = []\n",
    "\n",
    "    for item in runner_list:\n",
    "        if 'ltp' in item[0]:\n",
    "            list.append([item[0]['ltp'], item[1]])\n",
    "\n",
    "    del list[-1]\n",
    "    arr = np.array(list)\n",
    "    arr = arr[arr[:, 0] != 0]\n",
    "    implied_odds = np.array([1 / arr[:, 0], arr[:, 1]]).T\n",
    "\n",
    "    return implied_odds\n",
    "\n",
    "\n",
    "# Find avg ltp odds\n",
    "def odds_avg(runner_1, runner_2, r1_result):\n",
    "    if runner_1[-1, 1] > runner_2[-1, 1]:\n",
    "        if runner_1[1, 1] > runner_2[1, 1]:\n",
    "            timestamps = np.arange(round(runner_2[1, 1], -2), round(runner_1[-1, 1] + 1, -2), 100)\n",
    "        else:\n",
    "            timestamps = np.arange(round(runner_1[1, 1], -2), round(runner_1[-1, 1] + 1, -2), 100)\n",
    "    else:\n",
    "        if runner_1[1, 1] > runner_2[1, 1]:\n",
    "            timestamps = np.arange(round(runner_2[1, 1], -2), round(runner_2[-1, 1] + 1, -2), 100)\n",
    "        else:\n",
    "            timestamps = np.arange(round(runner_1[1, 1], -2), round(runner_2[-1, 1] + 1, -2), 100)\n",
    "\n",
    "    odds = np.zeros(np.shape(timestamps))\n",
    "    df_timestamps = pd.Series(timestamps)\n",
    "\n",
    "    df_datetime = pd.to_datetime(df_timestamps, unit='ms')\n",
    "\n",
    "    df = pd.DataFrame({'runner 1': odds, '1 - runner 2': odds}, index=df_datetime)\n",
    "\n",
    "    for index, time in enumerate(runner_1[:, 1]):\n",
    "        df['runner 1'].loc[pd.to_datetime(round(time, -2), unit='ms')] = runner_1[index, 0]\n",
    "\n",
    "    for index, time in enumerate(runner_2[:, 1]):\n",
    "        df['1 - runner 2'].loc[pd.to_datetime(round(time, -2), unit='ms')] = 1 - runner_2[index, 0]\n",
    "\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "    df.interpolate(method='time', limit_direction='both', inplace=True)\n",
    "    df['avg'] = df.mean(axis=1)\n",
    "    df_avg_odds = df.resample('2000ms').last()\n",
    "    last_index = df_avg_odds.last_valid_index() + pd.Timedelta(2, 'sec')\n",
    "    final_index = last_index + pd.Timedelta(12, 'sec')\n",
    "    df_datetime = pd.date_range(last_index, final_index, freq='2000ms')\n",
    "    print(df_datetime)\n",
    "    if r1_result == 'WINNER':\n",
    "        df_ones = pd.DataFrame({'runner 1': np.ones(7), '1 - runner 2': np.ones(7), 'avg': np.ones(7)}, index=df_datetime)\n",
    "        df_avg_odds = pd.concat([df_avg_odds, df_ones])\n",
    "    else:\n",
    "        df_zeros = pd.DataFrame({'runner 1': np.zeros(7), '1 - runner 2': np.zeros(7), 'avg': np.zeros(7)}, index=df_datetime)\n",
    "        df_avg_odds = pd.concat([df_avg_odds, df_zeros])\n",
    "    print(df_avg_odds)\n",
    "    return df_avg_odds\n",
    "\n",
    "def get_best_pricevol(runner_list, price, vol):\n",
    "# Function to get best lay and back information\n",
    "    back_list = []\n",
    "    lay_list = []\n",
    "\n",
    "    back_vol = []\n",
    "    lay_vol = []\n",
    "\n",
    "    for item in runner_list:\n",
    "        if 'atl' in item[0]:\n",
    "            if len(item[0]['atl']) > 1:\n",
    "                temp = []\n",
    "                for i in item[0]['atl']:\n",
    "                    if i[1] != 0:\n",
    "                        temp.append(i[0])\n",
    "                if temp:\n",
    "                    temp = np.array(temp)\n",
    "                    back_list.append([temp.min(), item[1]])\n",
    "                    back_vol.append([item[0]['atl'][temp.argmax()][1], item[1]])\n",
    "            else:\n",
    "                if item[0]['atl'][0][1] != 0:\n",
    "                    back_list.append([item[0]['atl'][0][0], item[1]])\n",
    "                    back_vol.append([item[0]['atl'][0][1], item[1]])\n",
    "\n",
    "    for item in runner_list:\n",
    "        if 'atb' in item[0]:\n",
    "            if len(item[0]['atb']) > 1:\n",
    "                temp = []\n",
    "                for i in item[0]['atb']:\n",
    "                    if i[1] != 0:\n",
    "                        temp.append(i[0])\n",
    "                if temp:\n",
    "                    temp = np.array(temp)\n",
    "                    lay_list.append([temp.max(), item[1]])\n",
    "                    lay_vol.append([item[0]['atb'][temp.argmax()][1], item[1]])\n",
    "            else:\n",
    "                if item[0]['atb'][0][1] != 0:\n",
    "                    lay_list.append([item[0]['atb'][0][0], item[1]])\n",
    "                    lay_vol.append([item[0]['atb'][0][1], item[1]])\n",
    "\n",
    "    del back_list[-1], lay_list[-1], back_vol[-1], lay_vol[-1]\n",
    "\n",
    "    back_vol_arr = np.array(back_vol)\n",
    "    lay_vol_arr = np.array(lay_vol)\n",
    "    back_arr = np.array(back_list)\n",
    "    lay_arr = np.array(lay_list)\n",
    "\n",
    "    back_series = pd.Series(back_arr[:, 0], index=pd.to_datetime(back_arr[:, 1], unit='ms'))\n",
    "    lay_series = pd.Series(lay_arr[:, 0], index=pd.to_datetime(lay_arr[:, 1], unit='ms'))\n",
    "    back_vol_series = pd.Series(back_vol_arr[:, 0], index=pd.to_datetime(back_vol_arr[:, 1], unit='ms'))\n",
    "    lay_vol_series = pd.Series(lay_vol_arr[:, 0], index=pd.to_datetime(lay_vol_arr[:, 1], unit='ms'))\n",
    "# Apply hampel filter to remove outliers\n",
    "    back_outliers = hampel(back_series, window_size=80)\n",
    "    lay_outliers = hampel(lay_series, window_size=80)\n",
    "    back_vol_outliers = hampel(back_vol_series, window_size=15)\n",
    "    lay_vol_outliers = hampel(lay_vol_series, window_size=15)\n",
    "\n",
    "    back_arr = np.delete(back_arr, back_outliers, axis=0)\n",
    "    lay_arr = np.delete(lay_arr, lay_outliers, axis=0)\n",
    "    back_vol_arr = np.delete(back_vol_arr, back_vol_outliers, axis=0)\n",
    "    lay_vol_arr = np.delete(lay_vol_arr, lay_vol_outliers, axis=0)\n",
    "\n",
    "    if price and not vol:\n",
    "        return back_arr, lay_arr\n",
    "    elif vol and not price:\n",
    "        return back_vol_arr, lay_vol_arr\n",
    "\n",
    "    return back_arr, lay_arr, back_vol_arr, lay_vol_arr\n",
    "\n",
    "def best_available_df(runner_list, start, end):\n",
    "# Get back and lay information and calculate spread and price up probability\n",
    "    end_time = end + pd.Timedelta(120, 'sec')\n",
    "    df_datetime = pd.date_range(start, end_time, freq='100ms')\n",
    "    df_datetime = df_datetime.floor('100ms')\n",
    "    dt_shape = np.zeros(df_datetime.shape)\n",
    "\n",
    "    back_arr, lay_arr, back_vol_arr, lay_vol_arr = get_best_pricevol(runner_list, True, True)\n",
    "\n",
    "    df = pd.DataFrame({'back': dt_shape, 'lay': dt_shape, 'back_vol': dt_shape, 'lay_vol': dt_shape}, index=df_datetime)\n",
    "\n",
    "    for index, time in enumerate(back_arr[:, 1]):\n",
    "        df['back'].loc[pd.to_datetime(round(time, -2), unit='ms')] = back_arr[index, 0]\n",
    "    for index, time in enumerate(lay_arr[:, 1]):\n",
    "        df['lay'].loc[pd.to_datetime(round(time, -2), unit='ms')] = lay_arr[index, 0]\n",
    "\n",
    "    for index, time in enumerate(back_vol_arr[:, 1]):\n",
    "        df['back_vol'].loc[pd.to_datetime(round(time, -2), unit='ms')] = back_vol_arr[index, 0]\n",
    "    for index, time in enumerate(lay_vol_arr[:, 1]):\n",
    "        df['lay_vol'].loc[pd.to_datetime(round(time, -2), unit='ms')] = lay_vol_arr[index, 0]\n",
    "\n",
    "    df.replace(0, np.nan, inplace=True)\n",
    "    df.interpolate(method='time', limit_direction='both', inplace=True)\n",
    "\n",
    "    _2000ms = df.index.floor('2000ms')\n",
    "    idx_back = df.groupby(_2000ms)['back'].idxmin()\n",
    "    idx_lay = df.groupby(_2000ms)['lay'].idxmax()\n",
    "    df = df.resample('2000ms').mean().assign(back=df.loc[idx_back]['back'].values,\n",
    "                                            back_vol=df.loc[idx_back]['back_vol'].values,\n",
    "                                            lay=df.loc[idx_lay]['lay'].values,\n",
    "                                            lay_vol=df.loc[idx_lay]['lay_vol'].values)\n",
    "\n",
    "    df_best = df.rolling('60S').mean()\n",
    "    df_best = df_best.loc[start:end]\n",
    "    # last_index = end + pd.Timedelta(1, 'sec')\n",
    "    # final_index = last_index + pd.Timedelta(59, 'sec')\n",
    "    # df_datetime_new = pd.date_range(last_index, final_index, freq='2000ms')\n",
    "    # print(end, last_index)\n",
    "    # if r1_result == 'WINNER':\n",
    "    #     df_ones = pd.DataFrame({'back': np.repeat(1000, 60), 'back_vol': np.zeros(60), 'lay': np.repeat(1000, 60), 'lay_vol': np.repeat(0.001, 60)}, index=df_datetime_new)\n",
    "    #     df_best = pd.concat([df_best, df_ones])\n",
    "    # else:\n",
    "    #     df_zeros = pd.DataFrame({'back': np.ones(60), 'back_vol': np.zeros(60), 'lay': np.ones(60), 'lay_vol': np.repeat(0.001, 60)}, index=df_datetime_new)\n",
    "    #     df_best = pd.concat([df, df_zeros])\n",
    "    df_best['back-lay avg'] = df_best[['back', 'lay']].mean(axis=1)\n",
    "    df_best['spread'] = df_best['back'] - df_best['lay']\n",
    "    df_best['vol diff'] = df_best['back_vol'] - df_best['lay_vol']\n",
    "    df_best['uncertainty'] = df_best['spread'] / df_best['back-lay avg']\n",
    "    df_pup = df_best['back_vol'] / ( df_best['back_vol'] + df_best['lay_vol'] )\n",
    "    df_pup.name = 'pup'\n",
    "    df_best = pd.concat([df_best, df_pup], axis=1)\n",
    "    df_best.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    return df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:18.312125Z",
     "end_time": "2023-04-28T16:14:19.960765Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = '1.145414064.json'\n",
    "data_list, runner_id, runner_id_2, r1_result, market_timestamp = get_data(file)\n",
    "runner_list_1 = get_list(runner_id, data_list, market_timestamp)\n",
    "runner_list_2 = get_list(runner_id_2, data_list, market_timestamp)\n",
    "runner_odds_1 = convert_odds(runner_list_1)\n",
    "runner_odds_2 = convert_odds(runner_list_2)\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(runner_odds_1[:, 1], runner_odds_1[:, 0])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(runner_odds_2[:, 1], runner_odds_2[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:20.510194Z",
     "end_time": "2023-04-28T16:14:23.087443Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = odds_avg(runner_odds_1, runner_odds_2, r1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:23.652792Z",
     "end_time": "2023-04-28T16:14:23.750056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df['avg'])\n",
    "first_odds = df['avg'].iloc[0:300].mean()\n",
    "print(first_odds)\n",
    "r1, r2 = score.get_serve_prob(first_odds)\n",
    "r1 = r1.values[0]\n",
    "r2 = r2.values[0]\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:24.658082Z",
     "end_time": "2023-04-28T16:14:49.598666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_score = score.get_score_time_series(r1, r2, df['avg'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:57.733301Z",
     "end_time": "2023-04-28T16:14:57.740000Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:14:59.048921Z",
     "end_time": "2023-04-28T16:14:59.186520Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "ax.plot(df['avg'])\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(df_score['r2_setscore'])\n",
    "ax2.plot(df_score['r1_setscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:15:03.362885Z",
     "end_time": "2023-04-28T16:15:13.399554Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = df.first_valid_index()\n",
    "end = df.last_valid_index()\n",
    "df_runner_1 = best_available_df(runner_list_1, start, end)\n",
    "df_runner_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:15:35.726563Z",
     "end_time": "2023-04-28T16:16:07.145960Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_runner_2 = best_available_df(runner_list_2, start, end)\n",
    "df_runner_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:16:21.575660Z",
     "end_time": "2023-04-28T16:16:21.694259Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_avg = df['avg']\n",
    "df_blodds = ( 1 / df_runner_1['back-lay avg'] + 1 - 1 / df_runner_2['back-lay avg'] ) / 2\n",
    "df_odds = pd.concat([df_avg, df_blodds], axis=1)\n",
    "df_odds.columns = ['ltp odds', 'back lay odds']\n",
    "df_odds\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_odds)\n",
    "plt.legend(['Odds inferred from best back and lay average', 'Odds inferred from traded average'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:16:22.496714Z",
     "end_time": "2023-04-28T16:16:22.904965Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_1[['back','lay']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_2[['back','lay']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_1[['uncertainty']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_2[['uncertainty']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:16:23.628998Z",
     "end_time": "2023-04-28T16:16:23.936096Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_1[['back_vol']])\n",
    "plt.plot(df_runner_1[['lay_vol']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_1[['vol diff']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_1[['pup']])\n",
    "plt.plot(df_odds['ltp odds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T16:16:25.109898Z",
     "end_time": "2023-04-28T16:16:25.482417Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_2[['back_vol']])\n",
    "plt.plot(df_runner_2[['lay_vol']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_2[['vol diff']])\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df_runner_2[['pup']])\n",
    "plt.plot(1 - df_odds['ltp odds'])\n",
    "df_total = pd.DataFrame({'lpt odds': df_odds['ltp odds'], 'r1 spread': df_runner_1['uncertainty'], 'r1 pup': df_runner_1['pup'], 'r2 spread': df_runner_2['uncertainty'], 'r2 pup': df_runner_2['pup'], 'r1_setscore': 3 - df_score['r1_setscore'], 'r2_setscore': 3 - df_score['r2_setscore']}, index=df_odds.index)\n",
    "df_total\n",
    "df_total.to_csv('Data/1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
